name: ğŸš€ CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly security scans
    - cron: '0 2 * * 1'

env:
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1

jobs:
  test:
    name: ğŸ§ª Tests & Code Quality
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.11', '3.12', '3.13']
        exclude:
          # Temporarily exclude Python 3.13 on Windows due to compatibility
          - os: windows-latest
            python-version: '3.13'

    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        allow-prereleases: true

    - name: ğŸ“¦ Cache Dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.local/share/pip-cache
          ${{ runner.os == 'Windows' && '~\AppData\Local\pip\Cache' || '' }}
          ${{ runner.os == 'macOS' && '~/Library/Caches/pip' || '' }}
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt', '**/setup.py') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: ğŸ”§ Install Dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-xdist pytest-mock
        pip install flake8 mypy bandit safety
        pip install coverage[toml] codecov
        # Install package in development mode
        pip install -e .

    - name: ğŸ¯ Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: ğŸ§ª Run Tests with pytest
      run: |
        # Run tests with coverage and parallel execution
        pytest \
          --cov=src/telegram_audio_downloader \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term \
          --cov-fail-under=80 \
          --junitxml=pytest-results.xml \
          -v \
          --tb=short \
          -x
      env:
        COVERAGE_FILE: .coverage.${{ matrix.os }}-${{ matrix.python-version }}

    - name: ğŸ“Š Upload Coverage Reports
      uses: codecov/codecov-action@v4
      if: always()
      with:
        file: ./coverage.xml
        flags: unittests,${{ matrix.os }},python${{ matrix.python-version }}
        name: codecov-${{ matrix.os }}-${{ matrix.python-version }}
        fail_ci_if_error: false
        verbose: true
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

    - name: ğŸ” Type Checking with mypy
      run: |
        mypy src/telegram_audio_downloader \
          --ignore-missing-imports \
          --strict-optional \
          --warn-redundant-casts \
          --warn-unused-ignores \
          --show-error-codes
      continue-on-error: true

    - name: ğŸ“Š Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          pytest-results.xml
          htmlcov/
          .coverage.*
        retention-days: 7

  performance:
    name: ğŸš€ Performance Tests
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'schedule'

    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: ğŸ”§ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler
        pip install -e .

    - name: ğŸš€ Run Performance Tests
      run: |
        # Create performance test if not exists
        mkdir -p tests/performance
        if [ ! -f tests/performance/test_performance.py ]; then
          cat > tests/performance/test_performance.py << 'EOF'
import pytest
import time
from telegram_audio_downloader.utils import sanitize_filename, format_file_size

def test_sanitize_filename_performance(benchmark):
    """Test filename sanitization performance."""
    result = benchmark(sanitize_filename, "Test (File) [Name] {2024}.mp3")
    assert result == "Test _File_ _Name_ _2024_.mp3"

def test_format_file_size_performance(benchmark):
    """Test file size formatting performance."""
    result = benchmark(format_file_size, 1073741824)  # 1GB
    assert "GB" in result
EOF
        fi
        
        # Run performance tests
        pytest tests/performance/ --benchmark-json=benchmark.json -v

    - name: ğŸ“Š Upload Performance Results
      uses: actions/upload-artifact@v4
      with:
        name: performance-results
        path: benchmark.json
        retention-days: 30

  code-quality:
    name: ğŸ” Code Quality Analysis
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better relevancy

    - name: ğŸ Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: ğŸ”§ Install Quality Tools
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install \
          black \
          isort \
          flake8 \
          mypy \
          bandit \
          safety \
          vulture \
          radon \
          pylint
        pip install -e .

    - name: ğŸ¨ Check Code Formatting (Black)
      run: |
        black --check --diff src/ tests/
      continue-on-error: true

    - name: ğŸ”„ Check Import Sorting (isort)
      run: |
        isort --check-only --diff src/ tests/
      continue-on-error: true

    - name: ğŸ¦… Find Dead Code (Vulture)
      run: |
        vulture src/ --min-confidence 80
      continue-on-error: true

    - name: ğŸ“Š Complexity Analysis (Radon)
      run: |
        radon cc src/ --min B
        radon mi src/ --min B
      continue-on-error: true

    - name: ğŸ” Static Analysis (Pylint)
      run: |
        pylint src/telegram_audio_downloader --output-format=json > pylint-report.json || true
      continue-on-error: true

    - name: ğŸ“Š Upload Quality Reports
      uses: actions/upload-artifact@v4
      with:
        name: code-quality-reports
        path: |
          pylint-report.json
        retention-days: 7

  docker:
    name: ğŸ³ Docker Build Test
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4

    - name: ğŸ—ï¸ Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: ğŸ³ Build Docker Image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: telegram-audio-downloader:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

  security:
    name: ğŸ”’ Security Checks
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: ğŸ” Run Bandit Security Linter
      run: |
        pip install bandit
        bandit -r src/telegram_audio_downloader -f json -o bandit-report.json
      continue-on-error: true

    - name: ğŸ“Š Upload Security Report
      uses: actions/upload-artifact@v3
      with:
        name: bandit-security-report
        path: bandit-report.json

  notify:
    name: ğŸ“¢ Notification
    runs-on: ubuntu-latest
    needs: [test, docker, security]
    if: always()

    steps:
    - name: ğŸ“Š Report Status
      run: |
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.docker.result }}" = "success" ]; then
          echo "âœ… All checks passed!"
        else
          echo "âŒ Some checks failed!"
          exit 1
        fi